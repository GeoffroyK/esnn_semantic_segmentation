import torch
import torch.nn as nn
import torch.nn.functional as F
from spikingjelly.activation_based import layer, neuron, surrogate

# SSAM: Spiking Spatially Adaptive Modulation
class SSAM(nn.Module):
    def __init__(self, channels):
        super(SSAM, self).__init__()
        self.conv1 = nn.Conv2d(channels, channels // 8, 1)
        self.conv2 = nn.Conv2d(channels // 8, channels, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        attention = self.sigmoid(self.conv2(F.relu(self.conv1(x))))
        return x * attention

# Spiking Convolution Block
class SpikingConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels, spike_fn=surrogate.Sigmoid()):
        super(SpikingConvBlock, self).__init__()
        self.block = nn.Sequential(
            layer.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels),
            neuron.IFNode(surrogate_function=spike_fn)
        )

    def forward(self, x):
        return self.block(x)

# Full SpikingEDN
class SpikingEDN(nn.Module):
    def __init__(self, input_channels=2, base_channels=32, num_classes=11):
        super(SpikingEDN, self).__init__()
        spike_fn = surrogate.Sigmoid()

        # Encoder
        self.enc1 = SpikingConvBlock(input_channels, base_channels, spike_fn)
        self.ssam1 = SSAM(base_channels)

        self.enc2 = SpikingConvBlock(base_channels, base_channels * 2, spike_fn)
        self.ssam2 = SSAM(base_channels * 2)

        self.enc3 = SpikingConvBlock(base_channels * 2, base_channels * 4, spike_fn)

        # Decoder
        self.up1 = nn.ConvTranspose2d(base_channels * 4, base_channels * 2, 2, stride=2)
        self.dec1 = SpikingConvBlock(base_channels * 4, base_channels * 2, spike_fn)

        self.up2 = nn.ConvTranspose2d(base_channels * 2, base_channels, 2, stride=2)
        self.dec2 = SpikingConvBlock(base_channels * 2, base_channels, spike_fn)

        # Output layer
        self.classifier = nn.Conv2d(base_channels, num_classes, kernel_size=1)

    def forward(self, x):
        # Encoding
        x1 = self.enc1(x)
        x1 = self.ssam1(x1)
        x2 = self.enc2(F.avg_pool2d(x1, 2))
        x2 = self.ssam2(x2)
        x3 = self.enc3(F.avg_pool2d(x2, 2))

        # Decoding
        d1 = self.up1(x3)
        d1 = torch.cat((d1, x2), dim=1)
        d1 = self.dec1(d1)

        d2 = self.up2(d1)
        d2 = torch.cat((d2, x1), dim=1)
        d2 = self.dec2(d2)

        out = self.classifier(d2)
        return out

if __name__ == "__main__":
    model = SpikingEDN(input_channels=2, base_channels=32, num_classes=11)
    print(f"Number of parameters in the model: {sum(p.numel() for p in model.parameters() if p.requires_grad)}")
    x = torch.randn(1, 2, 256, 256)  # Example input tensor
    output = model(x)  # Forward pass
    print(f"Output shape: {output.shape}")  # Output shape